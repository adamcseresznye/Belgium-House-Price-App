{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69412634-b259-4563-93c6-cf8064969b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import catboost\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn import (compose, feature_selection, impute, metrics,\n",
    "                     model_selection, pipeline, preprocessing)\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from tqdm import tqdm\n",
    "\n",
    "import creds\n",
    "import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008c9950-3e8c-4b25-9774-558a068ab8e0",
   "metadata": {},
   "source": [
    "# Retrieve and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed01bbdc-61df-4656-a86b-5aabfe45bac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.retrieve_data_from_MongoDB(\n",
    "    \"development\", \"BE_houses\", {\"day_of_retrieval\": \"2024-02-09\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b259e1b2-3e78-4612-a3fe-a29a543093b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.preprocess_and_split_data(df)\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab66bf9-4c93-4909-a88e-0977824a3261",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print(f\"Shape of X_train : {X_train.shape}, X_test : {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f733359-62bb-4201-a50b-a5ec4b51d3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isna().sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4faed5b-139a-47d4-8f64-2999912c5918",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL_FEATURES = X_train.select_dtypes(\"number\").columns.tolist()\n",
    "CATEGORICAL_FEATURES = X_train.select_dtypes(\"object\").columns.tolist()\n",
    "\n",
    "print(NUMERICAL_FEATURES)\n",
    "print(CATEGORICAL_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9db2b09-8efa-4118-aa12-228722c9bed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique values in categorical columns:\")\n",
    "for column in X_train[CATEGORICAL_FEATURES]:\n",
    "    print(f\"{column} : {X_train[column].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d189685-e9ec-4de5-b55d-038cf64eb27c",
   "metadata": {},
   "source": [
    "# Define a basic pipeline to use for feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec03948e-2467-4e07-a2a6-03b89b5b2d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(\n",
    "    numerical_features, categorical_features, additional_transformers=None\n",
    "):\n",
    "    numeric_transformer = pipeline.make_pipeline(\n",
    "        impute.SimpleImputer(strategy=\"median\"), preprocessing.StandardScaler()\n",
    "    )\n",
    "\n",
    "    categorical_transformer = pipeline.make_pipeline(\n",
    "        preprocessing.OrdinalEncoder(\n",
    "            handle_unknown=\"use_encoded_value\", unknown_value=999\n",
    "        ),\n",
    "        impute.SimpleImputer(strategy=\"median\"),\n",
    "    )\n",
    "\n",
    "    # Create a ColumnTransformer to handle both numerical and categorical features\n",
    "    transformers = [\n",
    "        (numeric_transformer, numerical_features),\n",
    "        (categorical_transformer, categorical_features),\n",
    "    ]\n",
    "\n",
    "    if additional_transformers is not None:\n",
    "        transformers.extend(additional_transformers)\n",
    "\n",
    "    preprocessor = compose.make_column_transformer(*transformers).set_output(\n",
    "        transform=\"pandas\"\n",
    "    )\n",
    "\n",
    "    model_pipeline = pipeline.make_pipeline(\n",
    "        preprocessor,\n",
    "        catboost.CatBoostRegressor(\n",
    "            iterations=100,\n",
    "            eval_fraction=0.2,\n",
    "            early_stopping_rounds=20,\n",
    "            silent=True,\n",
    "            use_best_model=True,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return model_pipeline\n",
    "\n",
    "\n",
    "create_pipeline(NUMERICAL_FEATURES, CATEGORICAL_FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651bd727-10ca-4812-982d-4d78c9b2429d",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "## Utilize categorical columns for grouping and transform each numerical variable based on the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08b0bf9-f050-4939-af5c-e31249a43e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalColumnTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, categorical_feature, numerical_feature, transform_type):\n",
    "        self.categorical_feature = categorical_feature\n",
    "        self.numerical_feature = numerical_feature\n",
    "        self.transform_type = transform_type\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Calculate transformation of numerical_feature based on training data\n",
    "        self.transform_values_ = X.groupby(self.categorical_feature)[\n",
    "            self.numerical_feature\n",
    "        ].agg(self.transform_type)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Apply transformation to dataset\n",
    "        return X.assign(\n",
    "            CategoricalColumnTransformer=lambda df: df[self.categorical_feature].map(\n",
    "                self.transform_values_\n",
    "            )\n",
    "        )[[\"CategoricalColumnTransformer\"]]\n",
    "\n",
    "    def get_feature_names_out(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26107caa-ae40-45c5-a51a-b6317ba59bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "\n",
    "results = []\n",
    "for categorical_feature in tqdm(CATEGORICAL_FEATURES, desc=\"Progress\"):\n",
    "    for numerical_feature in NUMERICAL_FEATURES:\n",
    "        feature_adder = CategoricalColumnTransformer(\n",
    "            categorical_feature=categorical_feature,\n",
    "            numerical_feature=numerical_feature,\n",
    "            transform_type=\"mean\",\n",
    "        )\n",
    "        additional_transformers = [\n",
    "            (feature_adder, [categorical_feature, numerical_feature])\n",
    "        ]\n",
    "        model_pipeline = create_pipeline(\n",
    "            numerical_features=NUMERICAL_FEATURES,\n",
    "            categorical_features=CATEGORICAL_FEATURES,\n",
    "            additional_transformers=additional_transformers,\n",
    "        )\n",
    "\n",
    "        scores = model_selection.cross_validate(\n",
    "            estimator=model_pipeline,\n",
    "            X=X_train,\n",
    "            y=y_train,\n",
    "            scoring=(\"r2\", \"neg_root_mean_squared_error\"),\n",
    "            cv=10,\n",
    "        )\n",
    "\n",
    "        result = (\n",
    "            categorical_feature,\n",
    "            numerical_feature,\n",
    "            np.mean(scores[\"test_neg_root_mean_squared_error\"]),\n",
    "            np.mean(scores[\"test_r2\"]),\n",
    "        )\n",
    "        results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faf1c3c-874d-4a12-baab-8ed9ad7a5710",
   "metadata": {},
   "source": [
    "**Best performances :**\n",
    "\n",
    "| categorical_feature  | numerical_feature | mean_OOFs |\n",
    "| :---------------- | :------: | :----: |\n",
    "| energy_class | zip_code | 0.092231\t\t  | \n",
    "| building_condition | construction_year | 0.092441  | \n",
    "| building_condition | number_of_frontages | 0.092443\t|\n",
    "\n",
    "\n",
    "The best result was obtained by taking the `energy_class` feature as categorical variable and calculating the mean of `zip_code`. The resulting OOF RMSE is *0.092231* which is slightly better than our base model (*0.09326*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31093121-8043-4683-9c5b-f6d2d0bb708b",
   "metadata": {},
   "source": [
    "## Generate bins from the continuous variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a1cb57-11d1-4934-89df-4d0aa9160bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinuousColumnTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        continuous_feature_to_bin,\n",
    "        continuous_feature_to_transfer,\n",
    "        transform_type,\n",
    "        n_bins,\n",
    "    ):\n",
    "        self.continuous_feature_to_bin = continuous_feature_to_bin\n",
    "        self.continuous_feature_to_transfer = continuous_feature_to_transfer\n",
    "        self.transform_type = transform_type\n",
    "        self.n_bins = n_bins\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Determine bin edges based on training data\n",
    "        self.bin_edges_ = pd.qcut(\n",
    "            x=X[self.continuous_feature_to_bin],\n",
    "            q=self.n_bins,\n",
    "            retbins=True,\n",
    "            duplicates=\"drop\",\n",
    "        )[1]\n",
    "\n",
    "        # Calculate transformation of continuous_feature_to_transfer based on training data\n",
    "        self.transform_values_ = (\n",
    "            X.assign(\n",
    "                binned_continuous_feature=lambda df: pd.cut(\n",
    "                    df[self.continuous_feature_to_bin],\n",
    "                    bins=self.bin_edges_,\n",
    "                    labels=False,\n",
    "                )\n",
    "            )\n",
    "            .groupby(\"binned_continuous_feature\")[self.continuous_feature_to_transfer]\n",
    "            .agg(self.transform_type)\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Apply binning and transformation to dataset\n",
    "        return X.assign(\n",
    "            binned_continuous_feature=lambda df: pd.cut(\n",
    "                df[self.continuous_feature_to_bin], bins=self.bin_edges_, labels=False\n",
    "            )\n",
    "        ).assign(\n",
    "            ContinuousColumnTransformer=lambda df: df[\"binned_continuous_feature\"].map(\n",
    "                self.transform_values_\n",
    "            )\n",
    "        )[\n",
    "            [\"ContinuousColumnTransformer\"]\n",
    "        ]\n",
    "\n",
    "    def get_feature_names_out(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5d098e-3784-426d-ba85-43be5ee6bfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "\n",
    "optimal_bins = int(np.floor(np.log2(X_train.shape[0])) + 1)\n",
    "results = []\n",
    "# Combine the loops to have a single progress bar\n",
    "for discretized_continuous in tqdm(NUMERICAL_FEATURES, desc=\"Progress\"):\n",
    "    for transformed_continuous in NUMERICAL_FEATURES:\n",
    "        if discretized_continuous != transformed_continuous:\n",
    "            continuous_discretizer = ContinuousColumnTransformer(\n",
    "                continuous_feature_to_bin=discretized_continuous,\n",
    "                continuous_feature_to_transfer=transformed_continuous,\n",
    "                transform_type=\"mean\",\n",
    "                n_bins=optimal_bins,\n",
    "            )\n",
    "\n",
    "            additional_transformers = [\n",
    "                (\n",
    "                    continuous_discretizer,\n",
    "                    [discretized_continuous, transformed_continuous],\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            model_pipeline = create_pipeline(\n",
    "                numerical_features=NUMERICAL_FEATURES,\n",
    "                categorical_features=CATEGORICAL_FEATURES,\n",
    "                additional_transformers=additional_transformers,\n",
    "            )\n",
    "            scores = model_selection.cross_validate(\n",
    "                estimator=model_pipeline,\n",
    "                X=X_train,\n",
    "                y=y_train,\n",
    "                scoring=(\"r2\", \"neg_root_mean_squared_error\"),\n",
    "                cv=10,\n",
    "            )\n",
    "            result = (\n",
    "                discretized_continuous,\n",
    "                transformed_continuous,\n",
    "                np.mean(scores[\"test_neg_root_mean_squared_error\"]),\n",
    "                np.mean(scores[\"test_r2\"]),\n",
    "            )\n",
    "            results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605337ef-7355-4b19-9114-7ee551c23be9",
   "metadata": {},
   "source": [
    "**Best performances :**\n",
    "\n",
    "| discretized_continuous  | transformed_continuous | mean_OOFs |\n",
    "| :---------------- | :------: | :----: |\n",
    "| living_area | bathrooms | 0.092563\t  |\n",
    "| primary_energy_consumption | toilets | 0.092683  | \n",
    "| living_area | bedrooms | 0.092728  |\n",
    "\n",
    "\n",
    "The best result was obtained by taking the `living_area` feature as discretized continuous variable and calculating the mean of `bathrooms`. The resulting OOF RMSE is *0.092563* which is slightly better than our base model (*0.09326*).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9954a88-a17e-437a-9e46-21c4ec1a6624",
   "metadata": {},
   "source": [
    "## Introduce polynomial features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea16b391-afe7-4210-91db-196eb9146fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "results = []\n",
    "for numerical_feature in tqdm(NUMERICAL_FEATURES, desc=\"Progress\"):\n",
    "    \n",
    "    NEW_NUMERICAL_FEATURES = NUMERICAL_FEATURES.copy() \n",
    "    NEW_NUMERICAL_FEATURES.remove(numerical_feature)\n",
    "    \n",
    "    polyfeatures = pipeline.make_pipeline(\n",
    "                    impute.SimpleImputer(strategy=\"median\"),\n",
    "                    preprocessing.PolynomialFeatures(\n",
    "                        interaction_only=False, include_bias=False\n",
    "                    )\n",
    "                )\n",
    "    additional_transformers = [\n",
    "            (polyfeatures, [numerical_feature])\n",
    "        ]\n",
    "    \n",
    "    model_pipeline = create_pipeline(\n",
    "            numerical_features=NEW_NUMERICAL_FEATURES,\n",
    "            categorical_features=CATEGORICAL_FEATURES,\n",
    "            additional_transformers=additional_transformers,\n",
    "        )\n",
    "    \n",
    "    scores = model_selection.cross_validate(\n",
    "            estimator=model_pipeline,\n",
    "            X=X_train,\n",
    "            y=y_train,\n",
    "            scoring=(\"r2\", \"neg_root_mean_squared_error\"),\n",
    "            cv=10,\n",
    "        )\n",
    "    \n",
    "    result = (\n",
    "            numerical_feature,\n",
    "            np.mean(scores[\"test_neg_root_mean_squared_error\"]),\n",
    "            np.mean(scores[\"test_r2\"]),\n",
    "        )\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98df6e5-9014-4b35-9f63-c9df4cf3c2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).sort_values(by=2, ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4cbd1a-04cb-4049-80e2-edf004dcf2e5",
   "metadata": {},
   "source": [
    "**Best performances :**\n",
    "\n",
    "| numerical_col  | mean_OOFs |\n",
    "| :---------------- | :------: |\n",
    "| surface_of_the_plot | 0.093436\t | \n",
    "| zip_code | 0.093765\t | \n",
    "| construction_year | 0.093788| \n",
    "\n",
    "\n",
    "The best result was obtained by taking the polynomial feature of the `surface_of_the_plot`. The resulting OOF RMSE is *0.093436* which is slightly worse than our base model (*0.09326*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39fd630-d51d-4212-a78b-6f326e150696",
   "metadata": {},
   "source": [
    "## Implement other ideas derived from empirical observations or assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2ee1f1-2b76-4b97-99e5-69c81367bd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmpiricalTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Apply transformation to dataset\n",
    "        return X.assign(\n",
    "            energy_efficiency=lambda df: df.primary_energy_consumption / df.living_area,\n",
    "            total_rooms=lambda df: df.bathrooms + df.bedrooms,\n",
    "            bedroom_to_bathroom=lambda df: df.bedrooms / df.bathrooms,\n",
    "            area_per_room=lambda df: df.living_area / df.bedrooms,\n",
    "            plot_to_livings_area=lambda df: df.surface_of_the_plot / df.living_area,\n",
    "        ).loc[:, \"energy_efficiency\":]\n",
    "\n",
    "    def get_feature_names_out(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eacdd0d-3d18-4cbc-a0f1-a3b441a8ad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "numeric_transformer = pipeline.make_pipeline(\n",
    "        impute.SimpleImputer(strategy=\"median\"), preprocessing.StandardScaler()\n",
    "    )\n",
    "\n",
    "categorical_transformer = pipeline.make_pipeline(\n",
    "    preprocessing.OrdinalEncoder(\n",
    "        handle_unknown=\"use_encoded_value\", unknown_value=999\n",
    "    ),\n",
    "    impute.SimpleImputer(strategy=\"median\"),\n",
    ")\n",
    "\n",
    "empirical_transformer = pipeline.make_pipeline(\n",
    "    EmpiricalTransformer(),\n",
    "    impute.SimpleImputer(strategy=\"median\"),\n",
    ")\n",
    "\n",
    "# Create a ColumnTransformer to handle both numerical and categorical features\n",
    "transformers = [\n",
    "    (numeric_transformer, NUMERICAL_FEATURES),\n",
    "    (categorical_transformer, CATEGORICAL_FEATURES),\n",
    "    (empirical_transformer, [\"primary_energy_consumption\", \n",
    "                             \"living_area\", \"bathrooms\", \n",
    "                             \"bedrooms\", \"surface_of_the_plot\",\n",
    "                            ])\n",
    "    \n",
    "]\n",
    "\n",
    "preprocessor = compose.make_column_transformer(*transformers).set_output(\n",
    "    transform=\"pandas\"\n",
    ")\n",
    "\n",
    "results = []\n",
    "for column in temp_dataframe.columns[-5:]:\n",
    "\n",
    "    temp_dataframe = preprocessor.fit_transform(X_train)\n",
    "    \n",
    "    added_features = temp_dataframe.columns[-5:].tolist()\n",
    "    features_to_remove = added_features.copy()  \n",
    "    features_to_remove.remove(column)\n",
    "\n",
    "    new_X_train = temp_dataframe.drop(columns = features_to_remove)\n",
    "\n",
    "    regressor = catboost.CatBoostRegressor(\n",
    "                iterations=100,\n",
    "                eval_fraction=0.2,\n",
    "                early_stopping_rounds=20,\n",
    "                silent=True,\n",
    "                use_best_model=True)\n",
    "    \n",
    "    scores = model_selection.cross_validate(\n",
    "            estimator=regressor,\n",
    "            X=new_X_train,\n",
    "            y=y_train,\n",
    "            scoring=(\"r2\", \"neg_root_mean_squared_error\"),\n",
    "            cv=10,\n",
    "        )\n",
    "    \n",
    "    result = (\n",
    "            column,\n",
    "            np.mean(scores[\"test_neg_root_mean_squared_error\"]),\n",
    "            np.mean(scores[\"test_r2\"]),\n",
    "        )\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f893f0-9704-4d22-ad78-906a2343ac9e",
   "metadata": {},
   "source": [
    "**Best performances :**\n",
    "\n",
    "| feature  | mean_OOFs | \n",
    "| :---------------- | :------: | \n",
    "| 3__plot_to_livings_area | 0.093675\t | \n",
    "| 3__bedroom_to_bathroom | 0.093770\t | \n",
    "| 3__area_per_room | 0.094004|\n",
    "\n",
    "\n",
    "The best result was obtained was the incorporation of the `3__plot_to_livings_area` feature. The resulting OOF RMSE is *0.093675* which is slightly worse than our base model (*0.09326*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bcbc47-7df3-4f14-ad7c-753004e4c740",
   "metadata": {},
   "source": [
    "## Summarize the feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ecdb2b-4902-4a0e-8f70-963609fc1941",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={\n",
    "        \"condition\": [\n",
    "            \"Utilize categorical columns for grouping\",\n",
    "            \"Generate bins from the continuous variables\",\n",
    "            \"Introduce polynomial features\",\n",
    "            \"Empirical observations\",\n",
    "            \"Original\",\n",
    "        ],\n",
    "        \"mean_OOFs\": [0.092231, 0.092563, 0.093436, 0.093675, 0.09326],\n",
    "    }\n",
    ").sort_values(by=\"mean_OOFs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b18e4e-fb0f-48ac-9f61-67e54c4f6818",
   "metadata": {},
   "source": [
    "As you can see, with the exception of `Generate bins from the continuous variables`, the generated features scored better average validation RMSE values compared to the original setup, where no feature engineering applied. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57458324-a0e7-43a7-b3dd-c9cd7fbf0dbe",
   "metadata": {},
   "source": [
    "## Final feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc484f2-caf3-48b7-8b4a-e3ef0d158a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_column_transformer = CategoricalColumnTransformer(\n",
    "    categorical_feature=\"energy_class\",\n",
    "    numerical_feature=\"zip_code\",\n",
    "    transform_type=\"mean\",\n",
    ")\n",
    "\n",
    "continuous_discretizer = ContinuousColumnTransformer(\n",
    "    continuous_feature_to_bin=\"living_area\",\n",
    "    continuous_feature_to_transfer=\"bathrooms\",\n",
    "    transform_type=\"mean\",\n",
    "    n_bins=optimal_bins,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b513b9a-b247-458e-8043-86415081af88",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "results = []\n",
    "for n_features in tqdm(range(2, 17)):\n",
    "    numeric_transformer = pipeline.make_pipeline(\n",
    "        impute.SimpleImputer(strategy=\"median\"), preprocessing.StandardScaler()\n",
    "    )\n",
    "    \n",
    "    categorical_transformer = pipeline.make_pipeline(\n",
    "        preprocessing.OrdinalEncoder(\n",
    "            handle_unknown=\"use_encoded_value\", unknown_value=999\n",
    "        ),\n",
    "        impute.SimpleImputer(strategy=\"median\"),\n",
    "    )\n",
    "    \n",
    "    # Create a ColumnTransformer to handle both numerical and categorical features\n",
    "    transformers = [\n",
    "        (numeric_transformer, NUMERICAL_FEATURES),\n",
    "        (categorical_transformer, CATEGORICAL_FEATURES),\n",
    "        # (categorical_column_transformer, [\"energy_class\", \"zip_code\"]),\n",
    "        (continuous_discretizer, [\"living_area\", \"bathrooms\"])\n",
    "    ]\n",
    "    \n",
    "    preprocessor = compose.make_column_transformer(*transformers).set_output(\n",
    "        transform=\"pandas\"\n",
    "    )\n",
    "    \n",
    "    model_pipeline = pipeline.make_pipeline(\n",
    "        preprocessor,\n",
    "        feature_selection.RFE(\n",
    "            catboost.CatBoostRegressor(\n",
    "        iterations=100,\n",
    "        eval_fraction=0.2,\n",
    "        early_stopping_rounds=20,\n",
    "        silent=True,\n",
    "        use_best_model=True,\n",
    "    ),\n",
    "            n_features_to_select=n_features,\n",
    "        ),\n",
    "        catboost.CatBoostRegressor(\n",
    "        iterations=100,\n",
    "        eval_fraction=0.2,\n",
    "        early_stopping_rounds=20,\n",
    "        silent=True,\n",
    "        use_best_model=True,\n",
    "    )\n",
    "    )\n",
    "\n",
    "    # Get the names of the features selected\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "    selected_names = model_pipeline.named_steps[\n",
    "        \"rfe\"\n",
    "    ].get_feature_names_out()\n",
    "\n",
    "    scores = model_selection.cross_val_score(\n",
    "        estimator=model_pipeline,\n",
    "        X=X_train,\n",
    "        y=y_train,\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "        cv=10,\n",
    "    )\n",
    "    result = (n_features, selected_names, np.mean(scores), np.std(scores))\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefb1a81-ff69-4df0-8f77-c0e5f2c7157e",
   "metadata": {},
   "source": [
    "**Best performances :**\n",
    "\n",
    "| Condition  | n features to keep | n features to remove | AVG_test_RMSE |\n",
    "| :---------------- | :------: |  :------: |  :------: |\n",
    "| categorical_column_transformer AND continuous_discretizer|\t14 | 3 | 0.09281 | \n",
    "| categorical_column_transformer | 16\t | 0\t | 0.092231\t | \n",
    "| continuous_discretizer | 16\t | 0\t | 0.092563\t | \n",
    "\n",
    "Based on this experiment, we will only keep the categorical_column_transformer step with all other available features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51debf07-bd92-470d-bca4-fb10a108f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_column_transformer = pipeline.make_pipeline(\n",
    "    impute.SimpleImputer(strategy=\"most_frequent\"),\n",
    "    CategoricalColumnTransformer(\n",
    "        categorical_feature=\"energy_class\",\n",
    "        numerical_feature=\"zip_code\",\n",
    "        transform_type=\"mean\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "numeric_transformer = pipeline.make_pipeline(impute.SimpleImputer(strategy=\"median\"))\n",
    "\n",
    "categorical_transformer = pipeline.make_pipeline(\n",
    "    impute.SimpleImputer(strategy=\"most_frequent\"),\n",
    "    preprocessing.OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=999),\n",
    ")\n",
    "\n",
    "# Create a ColumnTransformer to handle both numerical and categorical features\n",
    "transformers = [\n",
    "    (numeric_transformer, NUMERICAL_FEATURES),\n",
    "    (categorical_transformer, CATEGORICAL_FEATURES),\n",
    "    (categorical_column_transformer, [\"energy_class\", \"zip_code\"]),\n",
    "]\n",
    "\n",
    "preprocessor = compose.make_column_transformer(*transformers).set_output(\n",
    "    transform=\"pandas\"\n",
    ")\n",
    "\n",
    "model_pipeline = pipeline.make_pipeline(\n",
    "    preprocessor,\n",
    "    catboost.CatBoostRegressor(\n",
    "        iterations=100,\n",
    "        eval_fraction=0.2,\n",
    "        early_stopping_rounds=20,\n",
    "        silent=True,\n",
    "        use_best_model=True,\n",
    "    ),\n",
    ")\n",
    "\n",
    "scores = model_selection.cross_val_score(\n",
    "    estimator=model_pipeline,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=10,\n",
    ")\n",
    "\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaffd47-61f8-438f-913d-97c4d8ef4856",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    \"catboostregressor__iterations\": stats.randint(100, 1000),\n",
    "    \"catboostregressor__learning_rate\": stats.loguniform(0.005, 0.01),\n",
    "    \"catboostregressor__depth\": stats.randint(2, 12),\n",
    "    \"catboostregressor__l2_leaf_reg\": stats.loguniform(1e-3, 1e3),\n",
    "    \"catboostregressor__border_count\": stats.randint(1, 255),\n",
    "    \"catboostregressor__bagging_temperature\": stats.uniform(0, 1),\n",
    "    \"catboostregressor__random_strength\": stats.uniform(0, 1),\n",
    "}\n",
    "\n",
    "grid = model_selection.RandomizedSearchCV(\n",
    "    estimator=model_pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    n_iter=50,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0726b9bd-46e2-4a5b-95bf-147b71a625ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627faa13-226b-40f4-b11c-0a833fab7767",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
