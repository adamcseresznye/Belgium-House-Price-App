{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69412634-b259-4563-93c6-cf8064969b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import catboost\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import (compose, feature_selection, impute, metrics,\n",
    "                     model_selection, pipeline, preprocessing)\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from tqdm import tqdm\n",
    "\n",
    "import creds\n",
    "import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008c9950-3e8c-4b25-9774-558a068ab8e0",
   "metadata": {},
   "source": [
    "# Retrieve and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed01bbdc-61df-4656-a86b-5aabfe45bac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.retrieve_data_from_MongoDB(\n",
    "    \"development\", \"BE_houses\", {\"day_of_retrieval\": \"2024-02-09\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b259e1b2-3e78-4612-a3fe-a29a543093b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.preprocess_and_split_data(df)\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab66bf9-4c93-4909-a88e-0977824a3261",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print(f\"Shape of X_train : {X_train.shape}, X_test : {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f733359-62bb-4201-a50b-a5ec4b51d3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isna().sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4faed5b-139a-47d4-8f64-2999912c5918",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL_FEATURES = X_train.select_dtypes(\"number\").columns.tolist()\n",
    "CATEGORICAL_FEATURES = X_train.select_dtypes(\"object\").columns.tolist()\n",
    "\n",
    "print(NUMERICAL_FEATURES)\n",
    "print(CATEGORICAL_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9db2b09-8efa-4118-aa12-228722c9bed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique values in categorical columns:\")\n",
    "for column in X_train[CATEGORICAL_FEATURES]:\n",
    "    print(f\"{column} : {X_train[column].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d189685-e9ec-4de5-b55d-038cf64eb27c",
   "metadata": {},
   "source": [
    "# Define a basic pipeline to use for feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec03948e-2467-4e07-a2a6-03b89b5b2d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(\n",
    "    numerical_features, categorical_features, additional_transformers=None\n",
    "):\n",
    "    numeric_transformer = pipeline.make_pipeline(\n",
    "        impute.SimpleImputer(strategy=\"median\"), preprocessing.StandardScaler()\n",
    "    )\n",
    "\n",
    "    categorical_transformer = pipeline.make_pipeline(\n",
    "        preprocessing.OrdinalEncoder(\n",
    "            handle_unknown=\"use_encoded_value\", unknown_value=999\n",
    "        ),\n",
    "        impute.SimpleImputer(strategy=\"median\"),\n",
    "    )\n",
    "\n",
    "    # Create a ColumnTransformer to handle both numerical and categorical features\n",
    "    transformers = [\n",
    "        (numeric_transformer, numerical_features),\n",
    "        (categorical_transformer, categorical_features),\n",
    "    ]\n",
    "\n",
    "    if additional_transformers is not None:\n",
    "        transformers.extend(additional_transformers)\n",
    "\n",
    "    preprocessor = compose.make_column_transformer(*transformers).set_output(\n",
    "        transform=\"pandas\"\n",
    "    )\n",
    "\n",
    "    model_pipeline = pipeline.make_pipeline(\n",
    "        preprocessor,\n",
    "        catboost.CatBoostRegressor(\n",
    "            iterations=100,\n",
    "            eval_fraction=0.2,\n",
    "            early_stopping_rounds=20,\n",
    "            silent=True,\n",
    "            use_best_model=True,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return model_pipeline\n",
    "\n",
    "\n",
    "create_pipeline(NUMERICAL_FEATURES, CATEGORICAL_FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651bd727-10ca-4812-982d-4d78c9b2429d",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "## Utilize categorical columns for grouping and transform each numerical variable based on the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08b0bf9-f050-4939-af5c-e31249a43e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalColumnTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, categorical_feature, numerical_feature, transform_type):\n",
    "        self.categorical_feature = categorical_feature\n",
    "        self.numerical_feature = numerical_feature\n",
    "        self.transform_type = transform_type\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Calculate transformation of numerical_feature based on training data\n",
    "        self.transform_values_ = X.groupby(self.categorical_feature)[\n",
    "            self.numerical_feature\n",
    "        ].agg(self.transform_type)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Apply transformation to dataset\n",
    "        return X.assign(\n",
    "            new_feature=lambda df: df[self.categorical_feature].map(\n",
    "                self.transform_values_\n",
    "            )\n",
    "        )[[\"new_feature\"]]\n",
    "\n",
    "    def get_feature_names_out(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26107caa-ae40-45c5-a51a-b6317ba59bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for categorical_feature in tqdm(CATEGORICAL_FEATURES, desc=\"Progress\"):\n",
    "    for numerical_feature in NUMERICAL_FEATURES:\n",
    "        feature_adder = CategoricalColumnTransformer(\n",
    "            categorical_feature=categorical_feature,\n",
    "            numerical_feature=numerical_feature,\n",
    "            transform_type=\"mean\",\n",
    "        )\n",
    "        additional_transformers = [\n",
    "            (feature_adder, [categorical_feature, numerical_feature])\n",
    "        ]\n",
    "        model_pipeline = create_pipeline(\n",
    "            numerical_features=NUMERICAL_FEATURES,\n",
    "            categorical_features=CATEGORICAL_FEATURES,\n",
    "            additional_transformers=additional_transformers,\n",
    "        )\n",
    "\n",
    "        scores = model_selection.cross_validate(\n",
    "            estimator=model_pipeline,\n",
    "            X=X_train,\n",
    "            y=y_train,\n",
    "            scoring=(\"r2\", \"neg_root_mean_squared_error\"),\n",
    "            cv=10,\n",
    "        )\n",
    "\n",
    "        result = (\n",
    "            categorical_feature,\n",
    "            numerical_feature,\n",
    "            np.mean(scores[\"test_neg_root_mean_squared_error\"]),\n",
    "            np.mean(scores[\"test_r2\"]),\n",
    "        )\n",
    "        results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6eeb1a-044e-40b9-b83a-93da0b688a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).sort_values(by=2, ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faf1c3c-874d-4a12-baab-8ed9ad7a5710",
   "metadata": {},
   "source": [
    "**Best performances :**\n",
    "\n",
    "| categorical_feature  | numerical_feature | mean_OOFs |\n",
    "| :---------------- | :------: | :----: |\n",
    "| energy_class | zip_code | 0.09337\t  | \n",
    "| building_condition | bedrooms | 0.093277  | \n",
    "| building_condition | living_area | 0.093333\t|\n",
    "\n",
    "\n",
    "The best result was obtained by taking the `heating_type` feature as categorical variable and calculating the mean of `bedrooms`. The resulting OOF RMSE is *0.09305* which is slightly better than our base model (*0.09326*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31093121-8043-4683-9c5b-f6d2d0bb708b",
   "metadata": {},
   "source": [
    "## Generate bins from the continuous variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a1cb57-11d1-4934-89df-4d0aa9160bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinuousColumnTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        continuous_feature_to_bin,\n",
    "        continuous_feature_to_transfer,\n",
    "        transform_type,\n",
    "        n_bins,\n",
    "    ):\n",
    "        self.continuous_feature_to_bin = continuous_feature_to_bin\n",
    "        self.continuous_feature_to_transfer = continuous_feature_to_transfer\n",
    "        self.transform_type = transform_type\n",
    "        self.n_bins = n_bins\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Determine bin edges based on training data\n",
    "        self.bin_edges_ = pd.qcut(\n",
    "            x=X[self.continuous_feature_to_bin],\n",
    "            q=self.n_bins,\n",
    "            retbins=True,\n",
    "            duplicates=\"drop\",\n",
    "        )[1]\n",
    "\n",
    "        # Calculate transformation of continuous_feature_to_transfer based on training data\n",
    "        self.transform_values_ = (\n",
    "            X.assign(\n",
    "                binned_continuous_feature=lambda df: pd.cut(\n",
    "                    df[self.continuous_feature_to_bin],\n",
    "                    bins=self.bin_edges_,\n",
    "                    labels=False,\n",
    "                )\n",
    "            )\n",
    "            .groupby(\"binned_continuous_feature\")[self.continuous_feature_to_transfer]\n",
    "            .agg(self.transform_type)\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Apply binning and transformation to dataset\n",
    "        return X.assign(\n",
    "            binned_continuous_feature=lambda df: pd.cut(\n",
    "                df[self.continuous_feature_to_bin], bins=self.bin_edges_, labels=False\n",
    "            )\n",
    "        ).assign(\n",
    "            new_feature=lambda df: df[\"binned_continuous_feature\"].map(\n",
    "                self.transform_values_\n",
    "            )\n",
    "        )[\n",
    "            [\"new_feature\"]\n",
    "        ]\n",
    "\n",
    "    def get_feature_names_out(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5d098e-3784-426d-ba85-43be5ee6bfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_bins = int(np.floor(np.log2(X_train.shape[0])) + 1)\n",
    "results = []\n",
    "# Combine the loops to have a single progress bar\n",
    "for discretized_continuous in tqdm(NUMERICAL_FEATURES, desc=\"Progress:\"):\n",
    "    for transformed_continuous in NUMERICAL_FEATURES:\n",
    "        if discretized_continuous != transformed_continuous:\n",
    "            continuous_discretizer = ContinuousColumnTransformer(\n",
    "                continuous_feature_to_bin=discretized_continuous,\n",
    "                continuous_feature_to_transfer=transformed_continuous,\n",
    "                transform_type=\"mean\",\n",
    "                n_bins=optimal_bins,\n",
    "            )\n",
    "\n",
    "            additional_transformers = [\n",
    "                (\n",
    "                    continuous_discretizer,\n",
    "                    [discretized_continuous, transformed_continuous],\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            model_pipeline = create_pipeline(\n",
    "                numerical_features=NUMERICAL_FEATURES,\n",
    "                categorical_features=CATEGORICAL_FEATURES,\n",
    "                additional_transformers=additional_transformers,\n",
    "            )\n",
    "            scores = model_selection.cross_validate(\n",
    "                estimator=model_pipeline,\n",
    "                X=X_train,\n",
    "                y=y_train,\n",
    "                scoring=(\"r2\", \"neg_root_mean_squared_error\"),\n",
    "                cv=10,\n",
    "            )\n",
    "            result = (\n",
    "                discretized_continuous,\n",
    "                transformed_continuous,\n",
    "                np.mean(scores[\"test_neg_root_mean_squared_error\"]),\n",
    "                np.mean(scores[\"test_r2\"]),\n",
    "            )\n",
    "            results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39bd339-740f-4d13-9525-42fd4a72c675",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).sort_values(by=2, ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605337ef-7355-4b19-9114-7ee551c23be9",
   "metadata": {},
   "source": [
    "**Best performances :**\n",
    "\n",
    "| discretized_continuous  | transformed_continuous | mean_OOFs |\n",
    "| :---------------- | :------: | :----: |\n",
    "| primary_energy_consumption | zip_code | -0.099286\t  |\n",
    "| primary_energy_consumption | living_area | -0.099351  | \n",
    "| primary_energy_consumption | surface_of_the_plot | -0.099562  |\n",
    "\n",
    "\n",
    "The best result was obtained by taking the `0.003809` feature as discretized continuous variable and calculating the mean of `zip_code`. The resulting OOF RMSE is *0.099286* which is slightly worse than our base model (*0.099271*).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9954a88-a17e-437a-9e46-21c4ec1a6624",
   "metadata": {},
   "source": [
    "## Introduce polynomial features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7bf4c6-a49f-49d7-a53b-af680af4e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FE_polynomial_features(\n",
    "    X: pd.DataFrame, y: pd.Series, combinations: int = 1\n",
    ") -> pd.DataFrame:\n",
    "    results = []\n",
    "\n",
    "    # Get a list of continuous and numerical columns\n",
    "    numerical_columns = X.select_dtypes(\"number\").columns\n",
    "\n",
    "    # Combine the loops to have a single progress bar\n",
    "    for numerical_col in tqdm(\n",
    "        list(itertools.combinations(numerical_columns, r=combinations))\n",
    "    ):\n",
    "        polyfeatures = compose.make_column_transformer(\n",
    "            (\n",
    "                pipeline.make_pipeline(\n",
    "                    impute.SimpleImputer(strategy=\"median\"),\n",
    "                    preprocessing.PolynomialFeatures(\n",
    "                        interaction_only=False, include_bias=False\n",
    "                    ),\n",
    "                ),\n",
    "                list(numerical_col),\n",
    "            ),\n",
    "            remainder=\"passthrough\",\n",
    "        ).set_output(transform=\"pandas\")\n",
    "\n",
    "        temp = polyfeatures.fit_transform(X)\n",
    "\n",
    "        new_numerical_features = temp.select_dtypes(\"number\").columns.tolist()\n",
    "        new_categorical_features = temp.select_dtypes(\"object\").columns.tolist()\n",
    "\n",
    "        # Define transformers for preprocessing\n",
    "        numeric_transformer = pipeline.make_pipeline(\n",
    "            impute.SimpleImputer(strategy=\"median\"), preprocessing.MinMaxScaler()\n",
    "        )\n",
    "\n",
    "        categorical_transformer = pipeline.make_pipeline(\n",
    "            preprocessing.OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
    "            impute.SimpleImputer(strategy=\"median\"),\n",
    "        )\n",
    "\n",
    "        # Create a ColumnTransformer to handle both numerical and categorical features\n",
    "        preprocessor = compose.make_column_transformer(\n",
    "            (numeric_transformer, new_numerical_features),\n",
    "            (categorical_transformer, new_categorical_features),\n",
    "        ).set_output(transform=\"pandas\")\n",
    "\n",
    "        model_pipeline = pipeline.make_pipeline(\n",
    "            preprocessor, catboost.CatBoostRegressor(iterations=100, silent=True)\n",
    "        )\n",
    "\n",
    "        scores = model_selection.cross_val_score(\n",
    "            estimator=model_pipeline,\n",
    "            X=temp,\n",
    "            y=y,\n",
    "            scoring=\"neg_root_mean_squared_error\",\n",
    "            cv=10,\n",
    "        )\n",
    "\n",
    "        # Store the results as a tuple\n",
    "        result = (numerical_col, np.mean(scores), np.std(scores))\n",
    "        results.append(result)\n",
    "\n",
    "        del temp, scores, result\n",
    "\n",
    "    result_df = pd.DataFrame(\n",
    "        results, columns=[\"numerical_col\", \"mean_OOFs\", \"std_OOFs\"]\n",
    "    )\n",
    "    result_df = result_df.sort_values(by=\"mean_OOFs\", ascending=False)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad4a47f-a7f9-49a7-88f3-231a650fcde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "FE_polynomial_features(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50f967b-3046-4d00-8fef-08b3701b3fd2",
   "metadata": {},
   "source": [
    "**Best performances :**\n",
    "\n",
    "| numerical_col  | mean_OOFs | std_OOFs |\n",
    "| :---------------- | :------: | :----: |\n",
    "| zip_code | -0.098392\t | 0.004372\t  |\n",
    "| bedrooms | -0.098816\t | 0.003782 |\n",
    "| primary_energy_consumption | -0.098900| 0.004057 |\n",
    "\n",
    "\n",
    "The best result was obtained by taking the polynomial feature of the `zip_code`. The resulting OOF RMSE is *0.098392* which is slightly better than our base model (*0.099271*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39fd630-d51d-4212-a78b-6f326e150696",
   "metadata": {},
   "source": [
    "## Implement other ideas derived from empirical observations or assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa00e1a-ffa6-45f4-a682-b1f85ebb4036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FE_ideas(X):\n",
    "    \"\"\"Performs additional feature engineering on the input DataFrame.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): The input DataFrame containing the original features.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with additional engineered features.\n",
    "\n",
    "    Example:\n",
    "        >>> engineered_data = FE_ideas(original_data)\n",
    "    \"\"\"\n",
    "    temp = X.assign(\n",
    "        energy_efficiency=lambda df: df.primary_energy_consumption / df.living_area,\n",
    "        total_rooms=lambda df: df.bathrooms + df.bedrooms,\n",
    "        bedroom_to_bathroom=lambda df: df.bedrooms / df.bathrooms,\n",
    "        area_per_room=lambda df: df.living_area / df.bedrooms,\n",
    "        plot_to_livings_area=lambda df: df.surface_of_the_plot / df.living_area,\n",
    "    )\n",
    "    return temp.loc[:, \"energy_efficiency\":]\n",
    "\n",
    "\n",
    "FE_ideas(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0380ea-9d02-4ae5-9092-9a9afc1bb2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FE_try_ideas(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Performs feature engineering experiments by adding new features and evaluating their impact on model performance.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): The input feature matrix.\n",
    "        y (pd.Series): The target variable.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the results of feature engineering experiments.\n",
    "\n",
    "    Example:\n",
    "        >>> results_df = FE_try_ideas(X, y)\n",
    "    \"\"\"\n",
    "    # Initialize a list to store results\n",
    "    results = []\n",
    "\n",
    "    # Apply additional feature engineering ideas\n",
    "    feature_df = FE_ideas(X)\n",
    "\n",
    "    for feature in tqdm(feature_df.columns):\n",
    "        # Concatenate the original features with the newly engineered feature\n",
    "        temp = pd.concat([X, feature_df[feature]], axis=\"columns\")\n",
    "\n",
    "        new_numerical_features = temp.select_dtypes(\"number\").columns.tolist()\n",
    "        new_categorical_features = temp.select_dtypes(\"object\").columns.tolist()\n",
    "\n",
    "        # Define transformers for preprocessing\n",
    "        numeric_transformer = pipeline.make_pipeline(\n",
    "            impute.SimpleImputer(strategy=\"median\"), preprocessing.MinMaxScaler()\n",
    "        )\n",
    "\n",
    "        categorical_transformer = pipeline.make_pipeline(\n",
    "            preprocessing.OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
    "            impute.SimpleImputer(strategy=\"median\"),\n",
    "        )\n",
    "\n",
    "        # Create a ColumnTransformer to handle both numerical and categorical features\n",
    "        preprocessor = compose.make_column_transformer(\n",
    "            (numeric_transformer, new_numerical_features),\n",
    "            (categorical_transformer, new_categorical_features),\n",
    "        ).set_output(transform=\"pandas\")\n",
    "\n",
    "        model_pipeline = pipeline.make_pipeline(\n",
    "            preprocessor, catboost.CatBoostRegressor(iterations=100, silent=True)\n",
    "        )\n",
    "\n",
    "        scores = model_selection.cross_val_score(\n",
    "            estimator=model_pipeline,\n",
    "            X=temp,\n",
    "            y=y,\n",
    "            scoring=\"neg_root_mean_squared_error\",\n",
    "            cv=10,\n",
    "        )\n",
    "\n",
    "        # Store the results as a tuple\n",
    "        result = (feature, np.mean(scores), np.std(scores))\n",
    "        results.append(result)\n",
    "\n",
    "        del temp, scores, result\n",
    "\n",
    "    result_df = pd.DataFrame(results, columns=[\"feature\", \"mean_OOFs\", \"std_OOFs\"])\n",
    "    result_df = result_df.sort_values(by=\"mean_OOFs\", ascending=False)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9659a50-c1db-419f-a336-dd41667065d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "\n",
    "df_FE_try_ideas = FE_try_ideas(X,y)\n",
    "df_FE_try_ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a150b4-7c89-4da6-af5d-ce254f9a8605",
   "metadata": {},
   "source": [
    "**Best performances :**\n",
    "\n",
    "| feature  | mean_OOFs | std_OOFs |\n",
    "| :---------------- | :------: | :----: |\n",
    "| energy_efficiency | -0.099122\t | 0.004271|\n",
    "| area_per_room | -0.099712\t | 0.003463 |\n",
    "| plot_to_livings_area | -0.099972| 0.004570 |\n",
    "\n",
    "\n",
    "The best result was obtained was the incorporation of the `energy_efficiency` feature. The resulting OOF RMSE is *0.099122* which is slightly better than our base model (*0.099271*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bcbc47-7df3-4f14-ad7c-753004e4c740",
   "metadata": {},
   "source": [
    "## Summarize the feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ecdb2b-4902-4a0e-8f70-963609fc1941",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={\n",
    "        \"condition\": [\n",
    "            \"Utilize categorical columns for grouping\",\n",
    "            \"Generate bins from the continuous variables\",\n",
    "            \"Introduce polynomial features\",\n",
    "            \"Empirical observations\",\n",
    "            \"Original\",\n",
    "        ],\n",
    "        \"mean_OOFs\": [0.099005, 0.099286, 0.098392, 0.099122, 0.099271],\n",
    "    }\n",
    ").sort_values(by=\"mean_OOFs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b18e4e-fb0f-48ac-9f61-67e54c4f6818",
   "metadata": {},
   "source": [
    "As you can see, with the exception of `Generate bins from the continuous variables`, the generated features scored better average validation RMSE values compared to the original setup, where no feature engineering applied. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57458324-a0e7-43a7-b3dd-c9cd7fbf0dbe",
   "metadata": {},
   "source": [
    "## Final feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c38f507-213a-4ada-8aa2-10f74bf1f57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.assign(\n",
    "            energy_efficiency=lambda df: X.primary_energy_consumption / X.living_area,\n",
    "            tr_prov_liv=X.groupby(\"province\")[\"living_area\"].transform(\"mean\"),\n",
    "            tr_heat_liv=X.groupby(\"heating_type\")[\"living_area\"].transform(\"mean\"),\n",
    "            tr_buil_energy=X.groupby(\"building_condition\")[\n",
    "                \"primary_energy_consumption\"\n",
    "            ].transform(\"mean\"),\n",
    "        )[[\"energy_efficiency\", \"tr_prov_liv\", \"tr_heat_liv\", \"tr_buil_energy\"]]\n",
    "\n",
    "    def get_feature_names_out(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce03a10-fed1-4b8c-9096-298c94a1f967",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_numerical_features = [\n",
    "    item\n",
    "    for item in X.select_dtypes(\"number\").columns.tolist()\n",
    "    if item not in [\"zip_code\", \"bedrooms\", \"primary_energy_consumption\"]\n",
    "]\n",
    "new_categorical_features = X.select_dtypes(\"object\").columns.tolist()\n",
    "\n",
    "polyfeatures = pipeline.make_pipeline(\n",
    "    impute.SimpleImputer(strategy=\"median\"),\n",
    "    preprocessing.PolynomialFeatures(interaction_only=False, include_bias=False),\n",
    "    preprocessing.MinMaxScaler(),\n",
    ")\n",
    "\n",
    "feature_adder = pipeline.make_pipeline(\n",
    "    FeatureAdder(),\n",
    "    impute.SimpleImputer(strategy=\"median\"),\n",
    "    preprocessing.MinMaxScaler(),\n",
    ")\n",
    "\n",
    "# Define transformers for preprocessing\n",
    "numeric_transformer = pipeline.make_pipeline(\n",
    "    impute.SimpleImputer(strategy=\"median\"), preprocessing.MinMaxScaler()\n",
    ")\n",
    "\n",
    "categorical_transformer = pipeline.make_pipeline(\n",
    "    preprocessing.OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
    "    impute.SimpleImputer(strategy=\"median\"),\n",
    ")\n",
    "\n",
    "# Create a ColumnTransformer to handle both numerical and categorical features\n",
    "preprocessor = compose.make_column_transformer(\n",
    "    (polyfeatures, [\"zip_code\", \"bedrooms\", \"primary_energy_consumption\"]),\n",
    "    (\n",
    "        feature_adder,\n",
    "        [\n",
    "            \"primary_energy_consumption\",\n",
    "            \"living_area\",\n",
    "            \"province\",\n",
    "            \"heating_type\",\n",
    "            \"building_condition\",\n",
    "        ],\n",
    "    ),\n",
    "    (numeric_transformer, new_numerical_features),\n",
    "    (categorical_transformer, new_categorical_features),\n",
    ").set_output(transform=\"pandas\")\n",
    "\n",
    "# model_pipeline = pipeline.make_pipeline(\n",
    "#     preprocessor, catboost.CatBoostRegressor(iterations=100, silent=True)\n",
    "# )\n",
    "\n",
    "# scores = model_selection.cross_val_score(\n",
    "#     estimator=model_pipeline,\n",
    "#     X=X,\n",
    "#     y=y,\n",
    "#     scoring=\"neg_root_mean_squared_error\",\n",
    "#     cv=10,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dde883-cd3a-44aa-ba1a-a778ea054721",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da05e033-a9dc-4d8f-a2db-89e9f3ad8545",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for n_features in tqdm(range(2, 55)):\n",
    "    model_pipeline = pipeline.make_pipeline(\n",
    "        preprocessor,\n",
    "        feature_selection.SelectFromModel(\n",
    "            catboost.CatBoostRegressor(iterations=100, silent=True),\n",
    "            max_features=n_features,\n",
    "        ),\n",
    "        catboost.CatBoostRegressor(iterations=100, silent=True),\n",
    "    )\n",
    "\n",
    "    # Get the names of the features selected\n",
    "    model_pipeline.fit(X, y)\n",
    "    selected_names = model_pipeline.named_steps[\n",
    "        \"selectfrommodel\"\n",
    "    ].get_feature_names_out()\n",
    "\n",
    "    scores = model_selection.cross_val_score(\n",
    "        estimator=model_pipeline,\n",
    "        X=X,\n",
    "        y=y,\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "        cv=10,\n",
    "    )\n",
    "    result = (n_features, selected_names, np.mean(scores), np.std(scores))\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db40b70-570b-4c52-8672-b655978112c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results, columns=[\"n_features\", \"selected_names\", \"mean_OOF\", \"STD_OOF\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f915357-147e-475e-ad15-c1b9eb5dbaa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6521fd-aadc-4a5e-b5e4-53821434dbfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61c6d42-2069-4e8a-8ca5-1d216a9163db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b25c65-b69d-4500-bb10-2d611b8694df",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = [\n",
    "    preprocessing.OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
    "    preprocessing.OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=999),\n",
    "    preprocessing.TargetEncoder(target_type=\"continuous\"),\n",
    "]\n",
    "imputers = [impute.SimpleImputer(strategy=\"median\"), impute.KNNImputer()]\n",
    "scalers = [\n",
    "    preprocessing.StandardScaler(),\n",
    "    preprocessing.MinMaxScaler(),\n",
    "    preprocessing.RobustScaler(),\n",
    "]\n",
    "\n",
    "# Extract numerical and categorical feature names\n",
    "NUMERICAL_FEATURES = X.select_dtypes(\"number\").columns.tolist()\n",
    "CATEGORICAL_FEATURES = X.select_dtypes(\"object\").columns.tolist()\n",
    "\n",
    "results = []\n",
    "\n",
    "# Iterate over the imputers, encoders and scalers\n",
    "for imputer in imputers:\n",
    "    for encoder in encoders:\n",
    "        for scaler in tqdm(scalers):\n",
    "            # Define transformers for preprocessing\n",
    "            numeric_transformer = pipeline.make_pipeline(imputer, scaler)\n",
    "            categorical_transformer = pipeline.make_pipeline(encoder, imputer)\n",
    "\n",
    "            # Create a ColumnTransformer to handle both numerical and categorical features\n",
    "            preprocessor = compose.make_column_transformer(\n",
    "                (numeric_transformer, NUMERICAL_FEATURES),\n",
    "                (categorical_transformer, CATEGORICAL_FEATURES),\n",
    "            )\n",
    "            model_pipeline = pipeline.make_pipeline(\n",
    "                preprocessor, catboost.CatBoostRegressor(iterations=10, silent=True)\n",
    "            )\n",
    "            scores = model_selection.cross_val_score(\n",
    "                estimator=model_pipeline,\n",
    "                X=X,\n",
    "                y=y,\n",
    "                scoring=\"neg_root_mean_squared_error\",\n",
    "                cv=10,\n",
    "            )\n",
    "\n",
    "            result = {\n",
    "                \"imputer\": str(imputer),\n",
    "                \"encoder\": str(encoder),\n",
    "                \"scaler\": str(scaler),\n",
    "                \"scores\": scores.tolist(),\n",
    "                \"mean_score\": np.mean(scores),\n",
    "                \"std_score\": np.std(scores),\n",
    "            }\n",
    "\n",
    "            results.append(result)\n",
    "\n",
    "pd.DataFrame(results).sort_values(by=\"mean_score\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
