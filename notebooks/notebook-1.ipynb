{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69412634-b259-4563-93c6-cf8064969b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import (compose, impute, metrics, model_selection, pipeline,\n",
    "                     preprocessing)\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "import creds\n",
    "import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008c9950-3e8c-4b25-9774-558a068ab8e0",
   "metadata": {},
   "source": [
    "# Retrieve and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed01bbdc-61df-4656-a86b-5aabfe45bac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.retrieve_data_from_MongoDB({\"day_of_retrieval\": \"2024-02-03\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b259e1b2-3e78-4612-a3fe-a29a543093b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.preprocess_and_split_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d189685-e9ec-4de5-b55d-038cf64eb27c",
   "metadata": {},
   "source": [
    "# Assess preprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3385a8a3-af4e-4d2e-a8ea-5638b92c7a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.assign(zip_code=lambda df: pd.to_numeric(df.zip_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68690570-37f7-432c-a637-b583ff08b7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numerical and categorical feature names\n",
    "NUMERICAL_FEATURES = X.select_dtypes(\"number\").columns.tolist()\n",
    "CATEGORICAL_FEATURES = X.select_dtypes(\"object\").columns.tolist()\n",
    "\n",
    "# Define transformers for preprocessing\n",
    "numeric_transformer = pipeline.make_pipeline(impute.SimpleImputer(strategy=\"median\"))\n",
    "\n",
    "categorical_transformer = pipeline.make_pipeline(\n",
    "    preprocessing.OneHotEncoder(handle_unknown=\"ignore\"),\n",
    "    impute.SimpleImputer(strategy=\"median\"),\n",
    ")\n",
    "\n",
    "# Create a ColumnTransformer to handle both numerical and categorical features\n",
    "preprocessor = compose.make_column_transformer(\n",
    "    (numeric_transformer, NUMERICAL_FEATURES),\n",
    "    (categorical_transformer, CATEGORICAL_FEATURES),\n",
    ")\n",
    "\n",
    "# Create a pipeline that includes the preprocessor and the model\n",
    "model_pipeline = pipeline.make_pipeline(\n",
    "    preprocessor, catboost.CatBoostRegressor(iterations=10, silent=True)\n",
    ")\n",
    "\n",
    "scores = model_selection.cross_val_score(\n",
    "    estimator=model_pipeline, X=X, y=y, scoring=\"neg_root_mean_squared_error\", cv=10\n",
    ")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e18246b-edc5-49f7-9afa-ae6c84b3e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer to enable target encoding within a pipeline\n",
    "\n",
    "\n",
    "class TargetEncoderWrapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, **te_args):\n",
    "        self.te_args = te_args\n",
    "        self.encoder = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.encoder = preprocessing.TargetEncoder(**self.te_args)\n",
    "        self.encoder.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.encoder.transform(X)\n",
    "\n",
    "\n",
    "encoders = [\n",
    "    preprocessing.OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
    "    preprocessing.OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=999),\n",
    "    TargetEncoderWrapper(target_type=\"continuous\"),\n",
    "]\n",
    "imputers = [impute.SimpleImputer(strategy=\"median\"), impute.KNNImputer()]\n",
    "scalers = [preprocessing.StandardScaler(), preprocessing.MinMaxScaler()]\n",
    "\n",
    "# Extract numerical and categorical feature names\n",
    "NUMERICAL_FEATURES = X.select_dtypes(\"number\").columns.tolist()\n",
    "CATEGORICAL_FEATURES = X.select_dtypes(\"object\").columns.tolist()\n",
    "\n",
    "results = []\n",
    "\n",
    "# Iterate over the imputers, encoders and scalers\n",
    "for imputer in imputers:\n",
    "    for encoder in encoders:\n",
    "        for scaler in scalers:\n",
    "            # Define transformers for preprocessing\n",
    "            numeric_transformer = pipeline.make_pipeline(imputer, scaler)\n",
    "            categorical_transformer = pipeline.make_pipeline(encoder, imputer)\n",
    "\n",
    "            # Create a ColumnTransformer to handle both numerical and categorical features\n",
    "            preprocessor = compose.make_column_transformer(\n",
    "                (numeric_transformer, NUMERICAL_FEATURES),\n",
    "                (categorical_transformer, CATEGORICAL_FEATURES),\n",
    "            )\n",
    "            model_pipeline = pipeline.make_pipeline(\n",
    "                preprocessor, catboost.CatBoostRegressor(iterations=100, silent=True)\n",
    "            )\n",
    "            scores = model_selection.cross_val_score(\n",
    "                estimator=model_pipeline,\n",
    "                X=X,\n",
    "                y=y,\n",
    "                scoring=\"neg_root_mean_squared_error\",\n",
    "                cv=10,\n",
    "            )\n",
    "\n",
    "            result = {\n",
    "                \"imputer\": str(imputer),\n",
    "                \"encoder\": str(encoder),\n",
    "                \"scaler\": str(scaler),\n",
    "                \"scores\": scores.tolist(),\n",
    "                \"mean_score\": np.mean(scores),\n",
    "                \"std_score\": np.std(scores),\n",
    "            }\n",
    "\n",
    "            results.append(result)\n",
    "\n",
    "pd.DataFrame(results).sort_values(by=\"mean_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b9ca82-317f-4f18-a2dc-3caebe7e5dbf",
   "metadata": {},
   "source": [
    "Best performance : \n",
    "* SimpleImputer, OneHotEncoder, MinMaxScaler = 0.099271\t0.004467\n",
    "* SimpleImputer, OneHotEncoder, StandardScaler = 0.099285\t0.004499\n",
    "* SimpleImputer, TargetEncoderWrapper, MinMaxScaler = 0.099382\t0.003905"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2f12a8-8f66-4535-88bd-e8419bb0d8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformers for preprocessing\n",
    "numeric_transformer = pipeline.make_pipeline(\n",
    "    impute.SimpleImputer(strategy=\"median\"), preprocessing.MinMaxScaler()\n",
    ")\n",
    "\n",
    "categorical_transformer = pipeline.make_pipeline(\n",
    "    preprocessing.OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
    "    impute.SimpleImputer(strategy=\"median\"),\n",
    ")\n",
    "\n",
    "# Create a ColumnTransformer to handle both numerical and categorical features\n",
    "preprocessor = compose.make_column_transformer(\n",
    "    (numeric_transformer, NUMERICAL_FEATURES),\n",
    "    (categorical_transformer, CATEGORICAL_FEATURES),\n",
    ").set_output(transform=\"pandas\")\n",
    "\n",
    "preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b25c65-b69d-4500-bb10-2d611b8694df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
